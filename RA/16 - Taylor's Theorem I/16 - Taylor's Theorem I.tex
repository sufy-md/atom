\input{../../preamble}
\begin{document}
\titleheader{Taylor's Theorem I}
\textbf{Prereqs} RA-15

Recall Lagrange's Theorem
\begin{SNP}{\thm}There is some $c \in (a, b)$ such that\end{SNP}\begin{equation}f(b) = f(a) + (b - a)\cdot f'(c)\end{equation}

and recall the definition of the derivative.
$$
f'(x_0) = \lim_{h \to 0}\frac{f(x_0 + h) - f(x_0)}{h}
$$
Observe that if $h$ is ``small enough'', we can deploy the approximation
\begin{equation}
f(x_0 + h) \approx f(x_0) + h\cdot f'(x_0)
\end{equation}
by rearranging the definition.

Compare $(1)$ and $(2)$. They look more or less similar. Suppose $a$ and $b$ are \emph{close} to each other and that $b = a + h$. Then, putting $(1)$ and $(2)$ side-by-side with $b - a = h$ and $x_0 = a$, we get
\begin{align*}
f(b) &= f(a) + (b - a)\cdot f'(c)\\
f(b) &\approx f(a) + (b - a)\cdot f'(a)
\end{align*}
Here's intuitively why these look so similar and how you should make sense of this situation. The approximation
$$
f(x) \approx f(a) + (x - a)\cdot f'(a)
$$
estimates the value of $f$ near $a$ with a linear function. Namely, if I want to guess the value of $f(a + h)$, I can use a straight line of slope $f'(a)$ passing through $(a, f(a))$
$$
f(a + h) \approx f(a) + h\cdot f'(a)
$$
Cool. But why did I start with Lagrange's Theorem? Well, Lagrange tells us that \emph{this approximation is in fact precise} if we just adjust the slope term, and that the correct slope is given by some $f'(c)$.
$$
f(a + h) = f(a) + h\cdot f'(c)
$$
Now, if $f'$ is continuous and $h$ is small, knowing $c \in (a, a + h)$ we can guess
$$
f'(a) \approx f'(c)
$$
Thus Lagrange's Theorem serves two purposes. It $(1)$ justifies that our approximation is reasonable, and $(2)$ assures us that our approximation can be made precise using some value of $f'$.
\newpage
But what if a linear approximation isn't good enough? What if I want a higher order, say, a quadratic approximation?
\begin{SWP}{\thm}{(Extended Lagrange) Let $f$ be twice differentiable on $(a, b)$ with $f'$ continuous on $[a, b]$. Then there is some $c\in (a, b)$ such that
$$
f(b) = f(a) + (b - a)\cdot f'(a) + \frac{(b - a)^2}{2}\cdot f''(c)
$$}Define
$$
F(x) = f(b) - f(x) - (b - x)\cdot f'(x)
$$
and observe $F(b) = 0$. Further,\begin{align*}
F'(x) &= - f'(x) - bf''(x) + f'(x) + xf''(x)\\
	  &= (x - b)\cdot f''(x)
\end{align*}
Now define
$$
g(x) = F(x) - \paran{\dfrac{b - x}{b - a}}^2F(a)
$$
Now observe that $g(a) = g(b) = 0$. Further,
\begin{align*}
g'(x) = F'(x) + 2\cdot F(a)\cdot \dfrac{(b - x)}{(b - a)^2}
\end{align*}
By Rolle's Theorem, there is some $c \in (a, b)$ such that $g'(c) = 0$. Substituting the previously calculated value of $F'(x)$,
\begin{align*}
0 = g'(c) &= F'(c) + 2\cdot F(a)\cdot \dfrac{(b - c)}{(b - a)^2}\\
          &= (c - b)\cdot f''(c) + 2\cdot F(a)\cdot \dfrac{(b - c)}{(b - a)^2}
\end{align*}
Transposing, we get
\begin{align*}
(b - c)\cdot f''(c) &= 2\cdot F(a)\cdot \dfrac{(b - c)}{(b - a)^2}\\
F(a) &= \dfrac{(b - a)^2}{2}\cdot f''(c)
\end{align*}
By definition of $F(x)$ we get
\begin{align*}
F(a) &= f(b) - f(a) - (b - a)f'(a)\\
\dfrac{(b - a)^2}{2}\cdot f''(c) &= f(b) - f(a) - (b - a)f'(a)
\end{align*}
And therefore there is some $c \in (a, b)$ such that
$$
f(b) = f(a) + (b - a)\cdot f'(a) + \dfrac{(b - a)^2}{2}\cdot f''(c)
$$
\end{SWP}
\newpage
At its core, this is the same statement as Lagrange's Theorem from an approximation perspective. Suppose I initiate a parabolic approximation at $a$
$$
f(a + h) \approx f(a) + h\cdot f'(a) + \dfrac{h^2}{2}\cdot f''(a)
$$
Then, the Extended Lagrange Theorem tells us that this approximation is good, and adjusting the last term makes it precise.
$$
f(a + h) = f(a) + h\cdot f'(a) + \dfrac{h^2}{2}\cdot f''(c)
$$
So we see that linear and quadratic approximations of $f(a+h)$ arenâ€™t just educated guesses, they're also \emph{guaranteed} to be accurate up to a final correction term. That correction depends on a higher derivative evaluated somewhere in the interval.

This generalises to $k-$degree polynomial approximations using $k-$th derivatives of $f$. We will explore a better phrasing of this idea and the proof of the general case, alongside the mysterious $2$ in the denominator of the $h^2$ term in RA-17.

\begin{SNP}{\xmp}Compare the quadratic approximation to the displacement equation
$$
s(t) = s(0) + u\cdot t + \dfrac{1}{2}\cdot a\cdot t^2
$$
By rewriting it as
$$
s(t) = s(0) + (t - 0)\cdot s'(0) + \dfrac{(t - 0)^2}{2}\cdot s''(0)
$$
\end{SNP}
\end{document}